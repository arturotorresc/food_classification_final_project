{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "proyecto_final_equipo2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qx3UXKFpoZaR"
      },
      "source": [
        "# Equipo 2\n",
        "## Miembros:\n",
        "### Jorge Arturo Torres Cruz - A01176590\n",
        "### Juan Manuel Pérez Font - A00819815\n",
        "### Sergio López Madriz - A01064725"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KtTK0qa1YjyU",
        "colab_type": "text"
      },
      "source": [
        "## Librerías"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kV0MqOuIxZW9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8c817650-cd57-43b8-ee8d-5a0ce88d6fd5"
      },
      "source": [
        "# Utilizaremos urllib para descargar las imagenes utilizando URLs obtenidos de ImageNet\n",
        "import urllib.request\n",
        "import os\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "import uuid\n",
        "from itertools import repeat\n",
        "from pathlib import Path\n",
        "import socket\n",
        "import cv2\n",
        "import numpy as np\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n",
        "socket.setdefaulttimeout(10)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pLuMXQr9uBie"
      },
      "source": [
        "## Recolección de datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fpOGbcf10rcm",
        "outputId": "668c5990-9b1a-4f7d-cc00-b8d245b57462",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# Para uso en colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "r2XP5CVRtiM1",
        "colab": {}
      },
      "source": [
        "data_directory = './drive/My Drive/food_classification/data'\n",
        "data_path = Path(data_directory)\n",
        "url_files = [x for x in data_path.iterdir() if x.is_file()]\n",
        "categories = ['wine', 'bubble_gum', 'dumplings', 'pizza', 'sandwich']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YVC89CCpw9X4",
        "outputId": "9cac2c93-580f-4974-b1d7-11d148b6e1a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# Iteramos por cada uno de los archivos y obtenemos los URLs de las imagenes.\n",
        "print(\"Reading files containing images urls\")\n",
        "urls = {}\n",
        "for file_path in url_files:\n",
        "    category = file_path.stem\n",
        "    with file_path.open() as f:\n",
        "        content = f.readlines()\n",
        "        content = [url.strip() for url in content]\n",
        "        print(\"Reading {} image urls ({})\".format(len(content), file_path))\n",
        "        urls[category] = content"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading files containing images urls\n",
            "Reading 1272 image urls (drive/My Drive/food_classification/data/dumplings.txt)\n",
            "Reading 1229 image urls (drive/My Drive/food_classification/data/sandwich.txt)\n",
            "Reading 1247 image urls (drive/My Drive/food_classification/data/wines.txt)\n",
            "Reading 1215 image urls (drive/My Drive/food_classification/data/pizza_urls.txt)\n",
            "Reading 1209 image urls (drive/My Drive/food_classification/data/bubble_gums.txt)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KGA4uySh9T34",
        "scrolled": true,
        "colab": {}
      },
      "source": [
        "working_urls = {\n",
        "    'bubble_gums': [],\n",
        "    'dumplings': [],\n",
        "    'pizza': [],\n",
        "    'sandwich': [],\n",
        "    'wines': []\n",
        "}\n",
        "\n",
        "def download_from_url(category_url):\n",
        "    category, url = category_url\n",
        "    print(f'Downloading {url} for category {category}')\n",
        "    try:\n",
        "        urllib.request.urlretrieve(url, f'{data_path}/{category}/{uuid.uuid4()}.jpg')\n",
        "        working_urls[category].append(url)\n",
        "        return url\n",
        "    except Exception as e:\n",
        "        print('Error')\n",
        "        return f'Error: {e}'\n",
        "\n",
        "def download_category_from_url(category, urls):\n",
        "    try:\n",
        "        print(f'Creating directory to store {category} images')\n",
        "        category_dir_path = data_path / category\n",
        "        category_dir_path.mkdir(parents=True)\n",
        "    except FileExistsError:\n",
        "        print(f'{category_dir_path} directory exists, continuing...')\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "    else:\n",
        "        print(f'Succesfully created {category}/ directory')\n",
        "    results = None\n",
        "    print(f'Downloading images for category {category}')\n",
        "    with ThreadPoolExecutor() as executor:\n",
        "        executor.map(download_from_url, zip(repeat(category), urls), timeout=10)\n",
        "    print(f'All images downloaded for category {category}')\n",
        "\n",
        "try:\n",
        "    data_path.mkdir()\n",
        "except FileExistsError:\n",
        "    print('data directory exists, continuing...')\n",
        "for category, category_urls in urls.items():\n",
        "    download_category_from_url(category, category_urls)\n",
        "print('All images downloaded into data folder')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "xdVvi-P3Yjyk",
        "colab_type": "code",
        "colab": {},
        "outputId": "0cc689c5-00a1-43ff-f5df-56f27fac1eb7"
      },
      "source": [
        "for category, urls in working_urls.items():\n",
        "    print(f'{category}: {len(urls)}')\n",
        "    # f=open(f'{category}.txt','w')\n",
        "    # l1 = map(lambda x:x+'\\n', urls)\n",
        "    # f.writelines(l1)\n",
        "    # f.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bubble_gums: 655\n",
            "dumplings: 411\n",
            "pizza: 841\n",
            "sandwich: 416\n",
            "wines: 536\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jjq1gfpZzZF4"
      },
      "source": [
        "## Generación de datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XWWMaKeBSvfo",
        "colab": {}
      },
      "source": [
        "# The default version of imgaug doesn't correctly support loading a 1d numpy array to augmenters\n",
        "!pip install imgaug==0.4.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "J1xWLUSdzcMI",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import imgaug.augmenters as iaa\n",
        "import cv2\n",
        "import glob"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "H2ptpvlJI8oG",
        "colab": {}
      },
      "source": [
        "def augment_data():\n",
        "  \"\"\"\n",
        "  Generates new data based on downloaded images by applying left-to-right flip\n",
        "  and Gaussian Blur.\n",
        "  \"\"\"\n",
        "  print('Augmenting data by flipping and Gaussian Blur...')\n",
        "  seq = iaa.Sequential([\n",
        "    iaa.Fliplr(0.5),\n",
        "    iaa.GaussianBlur(sigma=(0, 3.0))\n",
        "  ])\n",
        "\n",
        "  for category in categories:\n",
        "    batch = []\n",
        "    for filename in glob.iglob(f'{data_directory}/{category}/*'):\n",
        "      print(f'Reading {filename}')\n",
        "      try:\n",
        "        im = cv2.imread(filename)\n",
        "        cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
        "        batch.append(im)\n",
        "      except Exception as e:\n",
        "        print(f'Error on image: {filename}, continuing...')\n",
        "    images_aug = seq(images=np.array(batch))\n",
        "    for image in images_aug:\n",
        "      cv2.imwrite(f'{data_directory}/{category}/{uuid.uuid4()}.jpg', image)\n",
        "      print(f'Artificial data saved for category {category}')\n",
        "    print(f'=== {len(batch)} new images added to category {category} ===')\n",
        "\n",
        "augment_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8sdzAalYjyw",
        "colab_type": "text"
      },
      "source": [
        "## Separar train, test y validate\n",
        "### Separamos 80% train, 10% validate y 10% test para cada clase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rc0geNmHYjyw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "import shutil"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hD7SmWiYjyy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c0ebd07a-043b-4e39-820f-4d91df742a80"
      },
      "source": [
        "try:\n",
        "  os.mkdir(f'{data_directory}/train')\n",
        "except FileExistsError as e:\n",
        "  print('train directory already exists, continuing...')\n",
        "try:\n",
        "  os.mkdir(f'{data_directory}/test')\n",
        "except FileExistsError as e:\n",
        "  print('test directory already exists, continuing...')\n",
        "try:\n",
        "  os.mkdir(f'{data_directory}/valid')\n",
        "except FileExistsError as e:\n",
        "  print('valid directory already exists, continuing...')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train directory already exists, continuing...\n",
            "test directory already exists, continuing...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tE4Zo8XVYjy0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for category in categories:\n",
        "  try:\n",
        "    os.mkdir(f'{data_directory}/train/{category}')\n",
        "    os.mkdir(f'{data_directory}/valid/{category}')\n",
        "    os.mkdir(f'{data_directory}/test/{category}')\n",
        "  except FileExistsError as e:\n",
        "    print(f'{category} directory already exists, continuing...')\n",
        "\n",
        "  images = glob.glob(f'{data_directory}/{category}/*')\n",
        "  for i in random.sample(images, int(len(images) * 0.8)):\n",
        "    shutil.move(i, f'{data_directory}/train/{category}/')\n",
        "\n",
        "  images = glob.glob(f'{data_directory}/{category}/*') # Get files again, since they were moved\n",
        "  for i in random.sample(images, int(len(images) * 0.5)):\n",
        "    shutil.move(i, f'{data_directory}/valid/{category}/')\n",
        "\n",
        "  images = glob.glob(f'{data_directory}/{category}/*')\n",
        "  for i in random.sample(images, int(len(images))):\n",
        "    shutil.move(i, f'{data_directory}/test/{category}/')\n",
        "\n",
        "  # ====== Ocasiona problemas si se utiliza con Drive =========\n",
        "  # os.remove(f'{data_directory}/{category}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXOp1KvkcX-d",
        "colab_type": "text"
      },
      "source": [
        "# Aprendizaje"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mP9AsteNcaVX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creamos la CNN\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=3, activation='relu', input_shape=(150, 150, 3)))\n",
        "model.add(MaxPooling2D(2, 2))\n",
        "model.add(Conv2D(64, kernel_size=3, activation='relu'))\n",
        "model.add(MaxPooling2D(2, 2))\n",
        "model.add(Conv2D(128, kernel_size=3, activation='relu'))\n",
        "model.add(MaxPooling2D(2, 2))\n",
        "model.add(Conv2D(256, kernel_size=3, activation='relu'))\n",
        "model.add(MaxPooling2D(2, 2))\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(5, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCbKC9XwhHG4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUQ089MjfCQD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "save_path = './drive/My Drive/food_classification/data/model/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArwtguJ6hIC8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_saved_model():\n",
        "  loaded_model = None\n",
        "  try:\n",
        "    loaded_model = load_model(save_path)\n",
        "  except Exception as e:\n",
        "    print(\"An error ocurred while loading the model:\")\n",
        "    print(e)\n",
        "  return loaded_model\n",
        "\n",
        "# ======= Correr si ya se tiene un modelo parcialmente o completamente entrenado.\n",
        "# model = load_saved_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVw9SSwyj-Mq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c5123e20-66dd-4af0-f594-29646b8b886a"
      },
      "source": [
        "# image width\n",
        "rows = 150\n",
        "# image height\n",
        "cols = 150 \n",
        "channels = 3\n",
        "\n",
        "X_train = []\n",
        "y_train = []\n",
        "X_val = []\n",
        "y_val = []\n",
        "\n",
        "def get_category_class(category):\n",
        "  class_num = { 'wine': 0, 'bubble_gum': 1, 'dumplings': 2, 'pizza': 3, 'sandwich': 4}\n",
        "  return class_num[category]\n",
        "\n",
        "# Lee todos los nombres de las imagenes de un directorio y las guarda en una lista\n",
        "def read_imgs_and_set_class(dir_name, category):\n",
        "  path = '{}/{}/{}/'.format(data_directory, dir_name, category)\n",
        "  img_filenames = ['{}{}'.format(path, name) for name in os.listdir(path)]\n",
        "  print(\"Fetched {} image filenames for category {}\".format(len(img_filenames), category))\n",
        "  X = []\n",
        "  y = []\n",
        "  debug_counter = 0\n",
        "  for image in img_filenames:\n",
        "    try:\n",
        "      X.append(cv2.resize(cv2.imread(image, cv2.IMREAD_COLOR), (rows, cols), interpolation=cv2.INTER_CUBIC))\n",
        "      y.append(get_category_class(category))\n",
        "    except Exception as e:\n",
        "      pass\n",
        "    finally:\n",
        "      debug_counter += 1\n",
        "      if debug_counter % 150 == 0:\n",
        "        print(\"X is {} size and y is {} size\".format(len(X), len(y)))\n",
        "  print(\"Loaded X ({} data points) and y ({} data points) [{}]\".format(len(X), len(y), dir_name))\n",
        "  return (X, y)\n",
        "\n",
        "# Genera los datos para X_train y y_train\n",
        "def create_data_sets():\n",
        "  # Obtenemos la data de entrenamiento\n",
        "  for category in categories:\n",
        "    X, y = read_imgs_and_set_class('train', category)\n",
        "    X_train.extend(X)\n",
        "    y_train.extend(y)\n",
        "  \n",
        "  for category in categories:\n",
        "    X, y = read_imgs_and_set_class('val', category)\n",
        "    X_val.extend(X)\n",
        "    y_val.extend(y)\n",
        "  \n",
        "  print(\"Final X_train size: {}\".format(len(X_train)))\n",
        "  print(\"Final y_train size: {}\".format(len(y_train)))\n",
        "\n",
        "create_data_sets()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fetched 0 image filenames for category wine\n",
            "Loaded X (0 data points) and y (0 data points) [train]\n",
            "Fetched 1269 image filenames for category bubble_gum\n",
            "X is 148 size and y is 148 size\n",
            "X is 298 size and y is 298 size\n",
            "X is 447 size and y is 447 size\n",
            "X is 597 size and y is 597 size\n",
            "X is 747 size and y is 747 size\n",
            "X is 897 size and y is 897 size\n",
            "X is 1042 size and y is 1042 size\n",
            "X is 1182 size and y is 1182 size\n",
            "Loaded X (0 data points) and y (0 data points) [train]\n",
            "Fetched 1458 image filenames for category dumplings\n",
            "X is 145 size and y is 145 size\n",
            "X is 290 size and y is 290 size\n",
            "X is 440 size and y is 440 size\n",
            "X is 590 size and y is 590 size\n",
            "X is 740 size and y is 740 size\n",
            "X is 890 size and y is 890 size\n",
            "X is 1040 size and y is 1040 size\n",
            "X is 1185 size and y is 1185 size\n",
            "X is 1331 size and y is 1331 size\n",
            "Loaded X (1247 data points) and y (1247 data points) [train]\n",
            "Fetched 1506 image filenames for category pizza\n",
            "X is 145 size and y is 145 size\n",
            "X is 292 size and y is 292 size\n",
            "X is 442 size and y is 442 size\n",
            "X is 592 size and y is 592 size\n",
            "X is 742 size and y is 742 size\n",
            "X is 892 size and y is 892 size\n",
            "X is 1042 size and y is 1042 size\n",
            "X is 1192 size and y is 1192 size\n",
            "X is 1342 size and y is 1342 size\n",
            "X is 1491 size and y is 1491 size\n",
            "Loaded X (2685 data points) and y (2685 data points) [train]\n",
            "Fetched 1248 image filenames for category sandwich\n",
            "X is 142 size and y is 142 size\n",
            "X is 285 size and y is 285 size\n",
            "X is 428 size and y is 428 size\n",
            "X is 578 size and y is 578 size\n",
            "X is 728 size and y is 728 size\n",
            "X is 878 size and y is 878 size\n",
            "X is 1024 size and y is 1024 size\n",
            "X is 1167 size and y is 1167 size\n",
            "Loaded X (4182 data points) and y (4182 data points) [train]\n",
            "Fetched 0 image filenames for category wine\n",
            "Loaded X (5396 data points) and y (5396 data points) [train]\n",
            "Fetched 1269 image filenames for category bubble_gum\n",
            "X is 148 size and y is 148 size\n",
            "X is 298 size and y is 298 size\n",
            "X is 447 size and y is 447 size\n",
            "X is 597 size and y is 597 size\n",
            "X is 747 size and y is 747 size\n",
            "X is 897 size and y is 897 size\n",
            "X is 1042 size and y is 1042 size\n",
            "X is 1182 size and y is 1182 size\n",
            "Loaded X (5396 data points) and y (5396 data points) [train]\n",
            "Fetched 1458 image filenames for category dumplings\n",
            "X is 145 size and y is 145 size\n",
            "X is 290 size and y is 290 size\n",
            "X is 440 size and y is 440 size\n",
            "X is 590 size and y is 590 size\n",
            "X is 740 size and y is 740 size\n",
            "X is 890 size and y is 890 size\n",
            "X is 1040 size and y is 1040 size\n",
            "X is 1185 size and y is 1185 size\n",
            "X is 1331 size and y is 1331 size\n",
            "Loaded X (5396 data points) and y (5396 data points) [train]\n",
            "Fetched 1506 image filenames for category pizza\n",
            "X is 145 size and y is 145 size\n",
            "X is 292 size and y is 292 size\n",
            "X is 442 size and y is 442 size\n",
            "X is 592 size and y is 592 size\n",
            "X is 742 size and y is 742 size\n",
            "X is 892 size and y is 892 size\n",
            "X is 1042 size and y is 1042 size\n",
            "X is 1192 size and y is 1192 size\n",
            "X is 1342 size and y is 1342 size\n",
            "X is 1491 size and y is 1491 size\n",
            "Loaded X (5396 data points) and y (5396 data points) [train]\n",
            "Fetched 1248 image filenames for category sandwich\n",
            "X is 142 size and y is 142 size\n",
            "X is 285 size and y is 285 size\n",
            "X is 428 size and y is 428 size\n",
            "X is 578 size and y is 578 size\n",
            "X is 728 size and y is 728 size\n",
            "X is 878 size and y is 878 size\n",
            "X is 1024 size and y is 1024 size\n",
            "X is 1167 size and y is 1167 size\n",
            "Loaded X (5396 data points) and y (5396 data points) [train]\n",
            "Final X_train size: 5396\n",
            "Final y_train size: 5396\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SR-TpLSWl2JG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "303f4b5c-4a0a-44d6-fd0d-5974734e1016"
      },
      "source": [
        "# Checamos de que clases agregamos data\n",
        "print(set(y_train))\n",
        "print(set(y_val))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{1, 2, 3, 4}\n",
            "{1, 2, 3, 4}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9poVLdNCpra",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Copy de data por si se aplican transformaciones que no deve\n",
        "X_copy = X_train\n",
        "y_copy = y_train\n",
        "X_val_copy = X_val\n",
        "y_val_copy = y_val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tF9EFSdorDyu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Np array transformations\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "X_val = np.array(X_val)\n",
        "y_val = np.array(y_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nsNcxqeDBLz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convertimos la data a valores categoricos (para no tener 0,1,2,3,4)\n",
        "y_train = to_categorical(y_train)\n",
        "y_val = to_categorical(y_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rt3PFFLDDK4_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "48d7e03f-a052-430d-849f-eaf65f66df60"
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 148, 148, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 74, 74, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 72, 72, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 36, 36, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 34, 34, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 17, 17, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 15, 15, 256)       295168    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 12544)             0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 12544)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 5)                 62725     \n",
            "=================================================================\n",
            "Total params: 451,141\n",
            "Trainable params: 451,141\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-xisyFGDeOe",
        "colab_type": "text"
      },
      "source": [
        "## Entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QN-T9Bp7D1xQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Definimos la política para guardar a un modelo\n",
        "model_checkpoint_callback = ModelCheckpoint(\n",
        "    filepath=save_path,\n",
        "    save_weights_only=False,\n",
        "    monitor='val_acc',\n",
        "    mode='max',\n",
        "    save_best_only=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8a6qW-wyDfPd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "fd802cc1-642f-4581-9763-e1631704abf3"
      },
      "source": [
        "# Entrenamos al modelo\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=75, callbacks=[model_checkpoint_callback])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 5396 samples, validate on 5396 samples\n",
            "Epoch 1/75\n",
            "5396/5396 [==============================] - 300s 56ms/step - loss: 2.7044 - accuracy: 0.5669 - val_loss: 0.7692 - val_accuracy: 0.6929\n",
            "Epoch 2/75\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks/callbacks.py:707: RuntimeWarning: Can save best model only with val_acc available, skipping.\n",
            "  'skipping.' % (self.monitor), RuntimeWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " 640/5396 [==>...........................] - ETA: 3:25 - loss: 0.8534 - accuracy: 0.6687"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gJ9f1QIEYQO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}